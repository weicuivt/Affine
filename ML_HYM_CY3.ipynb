{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weicuivt/Affine/blob/master/ML_HYM_CY3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPHlHwjkqXS7"
      },
      "source": [
        "\n",
        "# ML HYM connection of a SU(3) bundle on CY3 surface "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v39HfhxqXS-"
      },
      "source": [
        "This introduction demonstrates how to use MLGeometry to: \n",
        "\n",
        "1. Generate a hypersurface.\n",
        "2. Build a bihomogeneous neural network and use that to compute numerical Calabi-Yau metrics. Test the performance with the testset. \n",
        "3. Define the bundle. \n",
        "4. Build a bihomogeneous neural network to learn the HYM connection.\n",
        "5. Test the performance of ML approach on testset and compare with the Donaldson's algorithm. \n",
        "\n",
        "\n",
        "https://blog.csdn.net/qq_37389133/article/details/79293430"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uUjalOlroxNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0161c300-f29d-4209-992d-2d8367878b68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Colab Notebooks/ML_HYM_CY3\n",
            "CHANGELOG.md  MLGeometry  ML_HYM_CY3.ipynb  numericalhym  training\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/My Drive/Colab Notebooks/ML_HYM_CY3\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mkVAwuOqXS-"
      },
      "source": [
        "## Configure imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMY24OSDqXS_"
      },
      "source": [
        "Import tensorflow_probability to use the L-BFGS optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u71-R8TRqXS_"
      },
      "outputs": [],
      "source": [
        "import sympy as sp\n",
        "import tensorflow as tf\n",
        "import tensorflow.python.keras.backend as K\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "import MLGeometry as mlg\n",
        "from MLGeometry import bihomoNN as bnn\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "import numericalhym.complex_derivatives as cd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjrnOG-hqXTC"
      },
      "source": [
        "## Define a hypersurface\n",
        "First define a set of coordinates and a function as sympy symbols:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqJCoCtfitde"
      },
      "source": [
        "Wei's comments: \n",
        "\n",
        "*  **Z**: homogeneous coordinates\n",
        "*  **f**: defining polynomial of hypersurface in P^4\n",
        "*   **n_pairs**: # of sample on each patch \n",
        "*   **HS_train**: a instance of hypersurface class \n",
        "*   **HS_test**:  a instance of hypersurface class\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EsYLHaecqXTC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1c1c04-b5e7-4e15-b08c-de6aebc23845"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Patches: 5\n",
            "Points on patch 1 : 2020\n",
            "Points on patch 2 : 1994\n",
            "Points on patch 3 : 1952\n",
            "Points on patch 4 : 2012\n",
            "Points on patch 5 : 2022\n",
            "Number of Patches: 4\n",
            "Points on patch 1 : 529\n",
            "Points on patch 2 : 483\n",
            "Points on patch 3 : 505\n",
            "Points on patch 4 : 503\n"
          ]
        }
      ],
      "source": [
        "z0, z1, z2, z3, z4 = sp.symbols('z0, z1, z2, z3, z4')\n",
        "Z = [z0,z1,z2,z3,z4]\n",
        "f = z0**5 + z1**5 + z2**5 + z3**5 + z4**5 + 0.5*z0*z1*z2*z3*z4\n",
        "\n",
        "n_pairs = 2000\n",
        "HS_train = mlg.hypersurface.Hypersurface(Z, f, n_pairs)\n",
        "HS_test = mlg.hypersurface.Hypersurface(Z, f, n_pairs)\n",
        "\n",
        "HS_train.list_patches()\n",
        "HS_train.patches[0].list_patches()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUrZtFDKqXTG"
      },
      "source": [
        "## Convert to Tensorflow Dataset\n",
        "\n",
        "*   **train_set**: Tensorflow Dataset for training \n",
        "*   **test_set**:  Tensorflow Dataset for testing \n",
        "*   **train_setM**:  minibatch dataset for metric training\n",
        "*   **test_setM**:   minibatch dataset for metric testing\n",
        "\n",
        "*   **points**:         points on the hypersurface  \n",
        "*   **Omega_Omegabar**: $\\small \\Omega \\wedge \\bar\\Omega$  \n",
        "*   **mass**:           mass  \n",
        "*   **restriction**:    restriction matrix 1 converting gradient of homogeneous coordinates to the coordinates on the hypersurface. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = mlg.tf_dataset.generate_dataset(HS_train)\n",
        "test_set = mlg.tf_dataset.generate_dataset(HS_test)\n",
        "\n",
        "train_set1 = train_set.shuffle(HS_train.n_points).batch(1000)\n",
        "test_set1 = test_set.shuffle(HS_test.n_points).batch(1000)\n",
        "\n",
        "points, Omega_Omegabar, mass, restriction = next(iter(train_set1))\n",
        "print(points[0])\n",
        "print(Omega_Omegabar[0])\n",
        "print(mass[0])\n",
        "print(restriction[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SUMyUPfmNq7",
        "outputId": "2688580e-2f91-4fa1-cff2-c9623ff1bba9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0.12615436+0.20734908j -0.92164963-0.16501299j  1.        +0.j\n",
            "  0.21388292-0.13885647j  0.6643115 -0.6734965j ], shape=(5,), dtype=complex64)\n",
            "tf.Tensor(0.061654072, shape=(), dtype=float32)\n",
            "tf.Tensor(1.2584366, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.        +0.j          0.        +0.j          0.        +0.j\n",
            "   0.        +0.j         -0.01340217+0.02222157j]\n",
            " [ 0.        +0.j          1.        +0.j          0.        +0.j\n",
            "   0.        +0.j          0.71680045+0.63524795j]\n",
            " [ 0.        +0.j          0.        +0.j          0.        +0.j\n",
            "   1.        +0.j         -0.02765523-0.01516288j]], shape=(3, 5), dtype=complex64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7kTwWbGqXTH"
      },
      "source": [
        "### Build a bihomogeneous neural network \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uehl0cb1qXTI"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense\n",
        "\n",
        "class Kahler_potential(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(Kahler_potential, self).__init__()\n",
        "        # The first layer transforms the complex points to the bihomogeneous form.\n",
        "        # The number of the outputs is d^2, where d is the number of coordinates.\n",
        "        self.bihomogeneous = bnn.Bihomogeneous()\n",
        "        self.layer1 = bnn.Dense(5**2, 70, activation=tf.square)\n",
        "        self.layer2 = bnn.Dense(70, 100, activation=tf.square)\n",
        "        self.layer3 = bnn.Dense(100, 1)\n",
        "        # self.layer1 = Dense( 70, activation=tf.square)\n",
        "        # self.layer2 = Dense( 100, activation=tf.square)\n",
        "        # self.layer3 = Dense( 1)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        x = self.bihomogeneous(inputs)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = tf.math.log(x)\n",
        "        return x\n",
        "\n",
        "model = Kahler_potential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XRmQ--g0NRC0"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def volume_form(points, Omega_Omegabar, mass, restriction):\n",
        "    \n",
        "    kahler_metric = mlg.complex_math.complex_hessian(tf.math.real(model(points)), points)\n",
        "    volume_form = tf.matmul(restriction, tf.matmul(kahler_metric, restriction, adjoint_b=True)) \n",
        "    volume_form = tf.math.real(tf.linalg.det(volume_form))\n",
        "    \n",
        "    # Calculate the normalization constant to make the overall integration as 1\n",
        "    # It is a batchwise calculation but we expect it to converge to a constant eventually\n",
        "    weights = mass / tf.reduce_sum(mass)\n",
        "    factor = tf.reduce_sum(weights * volume_form / Omega_Omegabar)\n",
        "    \n",
        "    return volume_form / factor\n",
        "\n",
        "@tf.function\n",
        "def get_metric(points, restriction):\n",
        "    \n",
        "    kahler_metric = mlg.complex_math.complex_hessian(tf.math.real(model(points)), points)\n",
        "    volume_form = tf.matmul(restriction, tf.matmul(kahler_metric, restriction, adjoint_b=True)) \n",
        "  \n",
        "    return volume_form\n",
        "\n",
        "\n",
        "def gradients_zbar(func, x):\n",
        "    dx_real = tf.gradients(tf.math.real(func), x)\n",
        "    dx_imag = tf.gradients(tf.math.imag(func), x)\n",
        "    return (dx_real + dx_imag*tf.constant(1j, dtype=x.dtype)) / 2\n",
        "\n",
        "@tf.autograph.experimental.do_not_convert\n",
        "def complex_hessian(func, x):\n",
        "    # Take a real function and calculate dzdzbar(f)\n",
        "    #grad = gradients_z(func, x)\n",
        "    grad = tf.math.conj(tf.gradients(func, x))\n",
        "    hessian = tf.stack([gradients_zbar(tmp[0], x)[0]\n",
        "                        for tmp in tf.unstack(grad, axis=2)],\n",
        "                       axis = 1) / 2.0\n",
        " \n",
        "    return hessian \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H6qhb37qXTJ"
      },
      "source": [
        "### Train the metric model with Adam \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ubhrlB6ZLsLn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "d21b3e81-583e-4e75-e1ba-be2f49cdd6a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 5: loss = 0.75131\n",
            "epoch 10: loss = 0.49746\n",
            "epoch 15: loss = 0.36619\n",
            "epoch 20: loss = 0.32214\n",
            "epoch 25: loss = 0.27885\n",
            "epoch 30: loss = 0.21667\n",
            "epoch 35: loss = 0.15926\n",
            "epoch 40: loss = 0.10493\n",
            "epoch 45: loss = 0.06642\n",
            "epoch 50: loss = 0.05976\n",
            "epoch 55: loss = 0.05704\n",
            "epoch 60: loss = 0.05220\n",
            "epoch 65: loss = 0.05162\n",
            "epoch 70: loss = 0.05099\n",
            "epoch 75: loss = 0.05015\n",
            "epoch 80: loss = 0.04942\n",
            "epoch 85: loss = 0.04868\n",
            "epoch 90: loss = 0.04710\n",
            "epoch 95: loss = 0.04430\n",
            "epoch 100: loss = 0.04342\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_func = mlg.loss.weighted_MAPE\n",
        "\n",
        "\n",
        "max_epochs = 100\n",
        "epoch = 0\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "            initial_learning_rate=0.1,\n",
        "            decay_steps = 100000,\n",
        "            decay_rate = 0.5)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "losses = []\n",
        "while epoch < max_epochs:\n",
        "    epoch = epoch + 1\n",
        "    for step, (points, Omega_Omegabar, mass, restriction) in enumerate(train_set1):\n",
        "        with tf.GradientTape() as tape:\n",
        "            det_omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
        "            loss = loss_func(Omega_Omegabar, det_omega, mass)\n",
        "            grads = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    if epoch % 5 == 0:\n",
        "        print(\"epoch %d: loss = %.5f\" % (epoch, loss))\n",
        "\n",
        "    losses.append(loss)\n",
        "\n",
        "# Learning curve\n",
        "plt.plot(range(epoch), losses)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.title('Training Curve');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2ErDhSyoAZr"
      },
      "source": [
        "##Test the metric model "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "m7XwulnIqXTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d886a00-b706-4218-f40e-1761d7ac40c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sigma_test = 0.04617\n",
            "sigma_train = 0.04415\n",
            "E_test = 0.00364\n",
            "E_train = 0.00337\n"
          ]
        }
      ],
      "source": [
        "def cal_total_loss(dataset, loss_function):\n",
        "    total_loss = tf.constant(0, dtype=tf.float32)\n",
        "    total_mass = tf.constant(0, dtype=tf.float32)\n",
        "    \n",
        "    for step, (points, Omega_Omegabar, mass, restriction) in enumerate(dataset):\n",
        "        det_omega = volume_form(points, Omega_Omegabar, mass, restriction)\n",
        "        mass_sum = tf.reduce_sum(mass)\n",
        "        total_loss += loss_function(Omega_Omegabar, det_omega, mass) * mass_sum\n",
        "        total_mass += mass_sum\n",
        "    total_loss = total_loss / total_mass\n",
        "\n",
        "    return total_loss.numpy()\n",
        "\n",
        "sigma_test = cal_total_loss(test_set1, mlg.loss.weighted_MAPE)\n",
        "sigma_test2 = cal_total_loss(train_set1, mlg.loss.weighted_MAPE)\n",
        "print(\"sigma_test = %.5f\" % sigma_test)\n",
        "print(\"sigma_train = %.5f\" % sigma_test2)\n",
        "\n",
        "\n",
        "E_test = cal_total_loss(test_set1, mlg.loss.weighted_MSE)\n",
        "E_test2 = cal_total_loss(train_set1, mlg.loss.weighted_MSE)\n",
        "print(\"E_test = %.5f\" % E_test)\n",
        "print(\"E_train = %.5f\" % E_test2)\n",
        "\n",
        "# def delta_sigma_square_test(y_true, y_pred, mass):\n",
        "#     weights = mass / K.sum(mass)\n",
        "#     return K.sum((K.abs(y_true - y_pred) / y_true - sigma_test)**2 * weights)\n",
        "\n",
        "# delta_sigma = cal_total_loss(test_set1, delta_sigma_square_test)\n",
        "# print(\"delta_simga = %.5f\" % delta_sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nAncd-miJAL"
      },
      "source": [
        "# Definition of the bundle\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MLLPPnO_iMNX"
      },
      "outputs": [],
      "source": [
        "z0, z1, z2, z3, z4 = sp.symbols('z0, z1, z2, z3, z4')\n",
        "Z = [z0,z1,z2,z3,z4]\n",
        "f = z0**5 + z1**5 + z2**5 + z3**5 + z4**5 + 0.5*z0*z1*z2*z3*z4\n",
        "\n",
        "Bterm = [1,1,1,1]\n",
        "Cterm = [4]\n",
        "rank = len(Bterm) - len(Cterm)\n",
        "\n",
        "# bundle maps \n",
        "Fmaps = [z0**3, z1**3, z2**3, z3**3]\n",
        "Fmaps_eval = sp.lambdify(Z, Fmaps, 'numpy')\n",
        "\n",
        "# gradient of bundle maps \n",
        "grads1 = sp.zeros(len(Z),rank)\n",
        "for i, s in enumerate(Z): \n",
        "  for j in range(rank):\n",
        "    grads1[i,j] = sp.diff(Fmaps[j]/Fmaps[0], s)\n",
        "\n",
        "grads2 = sp.zeros(len(Z),rank)\n",
        "for i, s in enumerate(Z): \n",
        "  for j in range(rank):\n",
        "    grads2[i,j] = sp.diff(Fmaps[j]/Fmaps[1], s)\n",
        "\n",
        "grads3 = sp.zeros(len(Z),rank)\n",
        "for i, s in enumerate(Z): \n",
        "  for j in range(rank):\n",
        "    grads3[i,j] = sp.diff(Fmaps[j]/Fmaps[2], s)\n",
        "\n",
        "grads4 = sp.zeros(len(Z),rank)\n",
        "for i, s in enumerate(Z): \n",
        "  for j in range(rank):\n",
        "    grads3[i,j] = sp.diff(Fmaps[j]/Fmaps[3], s)\n",
        "\n",
        "grads1_eval = sp.lambdify(Z, grads1, 'numpy')\n",
        "grads2_eval = sp.lambdify(Z, grads2, 'numpy')\n",
        "grads3_eval = sp.lambdify(Z, grads3, 'numpy')\n",
        "grads4_eval = sp.lambdify(Z, grads4, 'numpy')\n",
        "\n",
        "gradsFmaps_eval = [grads1_eval, grads2_eval, grads3_eval,grads4_eval]\n",
        "# print(type(gradsFmaps_eval[0]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXG4-0Xy-ZrA"
      },
      "source": [
        "# Add the addition data to Tensorflow dataset\n",
        "\n",
        "*   CY metric\n",
        "*   R2 matrix\n",
        "*   R3 matrix\n",
        "\n",
        "*   **datasetB**: Tensorflow Dataset for training bundle \n",
        "*   **train_setB**:  Tensorflow Dataset for training bundle in batch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getBundleSet(train_set):\n",
        "  train_set_list = list(train_set.as_numpy_iterator())\n",
        "  train_set_list2 = list(zip(*train_set_list))\n",
        "  \n",
        "  points = np.asarray(train_set_list2[0]) \n",
        "  Omega_Omegabar = np.asarray(train_set_list2[1]) \n",
        "  mass = np.asarray(train_set_list2[2]) \n",
        "  restriction = np.asarray(train_set_list2[3]) \n",
        "  cymetric = get_metric(points, restriction)\n",
        "  cymetric = np.asarray(cymetric) \n",
        "  # print(cymetric[0])\n",
        "  # print(len(cymetric))\n",
        "\n",
        "\n",
        "  maxframes = []\n",
        "  R2s = []\n",
        "  R3s = []\n",
        "\n",
        "  for pt in points:\n",
        "    # find the max frame \n",
        "    fmaps = Fmaps_eval(*pt)\n",
        "    fmaps_norm = np.absolute(fmaps).tolist()\n",
        "    max_frame_index = fmaps_norm.index(max(fmaps_norm))\n",
        "    maxframes. append(max_frame_index)\n",
        "\n",
        "    # get the R2 matrix \n",
        "    tr2 = (fmaps/fmaps[max_frame_index]).tolist()\n",
        "    r2 = np.delete(tr2,[max_frame_index])*(-1)\n",
        "    tR2 = np.array([[1+0j,0+0j,0+0j],[0+0j,1+0j,0+0j],[0+0j,0+0j,1+0j]])\n",
        "    R2 = np.insert(tR2, max_frame_index, r2, axis = 1)\n",
        "    R2s.append(R2)\n",
        "\n",
        "    # get the R3 matrix \n",
        "    tt = gradsFmaps_eval[max_frame_index](*pt)\n",
        "    tR3 = np.array([[0+0j,0+0j,0+0j],[0+0j,0+0j,0+0j],[0+0j,0+0j,0+0j]])\n",
        "    R3 = []\n",
        "    for i in range(len(Z)):\n",
        "      r3 = np.insert(tR3, max_frame_index, tt[i], axis = 1).tolist()\n",
        "      R3.append(r3)\n",
        "    R3s.append(R3)\n",
        "\n",
        "  # print(len(maxframes))\n",
        "  # print(len(R2s))\n",
        "  # print(R2s[1])\n",
        "  # print(len(R3s))\n",
        "  # print(R3s[1])\n",
        "\n",
        "\n",
        "  R2s = np.array(R2s).astype(np.complex64)\n",
        "  R3s = np.array(R3s).astype(np.complex64)\n",
        "  # print(type(R2s))\n",
        "  return tf.data.Dataset.from_tensor_slices((points, Omega_Omegabar, mass, restriction, cymetric, R2s, R3s))"
      ],
      "metadata": {
        "id": "lSFAjQOxzJaN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train set for bundle\n",
        "datasetBtrain = getBundleSet(train_set)\n",
        "datasetBtrain_batch = datasetBtrain.shuffle(HS_train.n_points).batch(1000)\n",
        "# test set for bundle\n",
        "datasetBtest = getBundleSet(test_set)\n",
        "datasetBtest_batch = datasetBtest.shuffle(HS_test.n_points).batch(1000)"
      ],
      "metadata": {
        "id": "o7AUitzGzwOz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NN for $S_B$\n",
        "\n",
        "## Setup the one-layer NN to test the lose function!!!\n"
      ],
      "metadata": {
        "id": "5eFm_dTQG7mo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SectionCY3B3(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(SectionCY3B3, self).__init__()\n",
        "        # The first layer transforms the complex points to the bihomogeneous form.\n",
        "        # The number of the outputs is d^2, where d is the number of coordinates.\n",
        "        self.bihomogeneous = bnn.Bihomogeneous()\n",
        "        self.layer1 = bnn.Dense(5**2, 100, activation=tf.square)\n",
        "        # self.layer2 = bnn.Dense(20, 30, activation=tf.square)\n",
        "        # self.layer3 = bnn.Dense(30, 50, activation=tf.square)\n",
        "        # self.layer4 = bnn.Dense(70, 80, activation=tf.square)\n",
        "        self.layer5 = bnn.Dense(100, 24)\n",
        "        \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        x = self.bihomogeneous(inputs)\n",
        "        x = self.layer1(x)\n",
        "        # x = self.layer2(x)\n",
        "        # x = self.layer3(x)\n",
        "        # x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        return x\n",
        "\n",
        "modelB3 = SectionCY3B3()"
      ],
      "metadata": {
        "id": "rsrMXoFEHsEi"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelB3(tpoints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "614Hr3qFS3YO",
        "outputId": "bade5090-9c78-444b-fa08-548c24815d11"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1000, 24), dtype=float32, numpy=\n",
              "array([[ 0.000934  ,  0.02531736,  0.15816261, ...,  0.11066248,\n",
              "        -0.09922633,  0.04656654],\n",
              "       [ 0.01132716, -0.02412906, -0.00195423, ...,  0.13350531,\n",
              "         0.03762478, -0.00941934],\n",
              "       [ 0.01100525,  0.15368535, -0.01219278, ...,  0.08476941,\n",
              "         0.06784526, -0.00657476],\n",
              "       ...,\n",
              "       [-0.26150307,  0.00304703,  0.01505594, ...,  0.18974409,\n",
              "        -0.17940539,  0.10390006],\n",
              "       [-0.06640899,  0.08208568, -0.04715982, ...,  0.07944436,\n",
              "         0.0460159 ,  0.08783581],\n",
              "       [ 0.10133582,  0.0314403 ,  0.10377097, ...,  0.11824094,\n",
              "        -0.12165272,  0.03133258]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tpoints[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6tsN4l1S_IH",
        "outputId": "7aebc229-3774-4ca6-e27c-cd07ae0cdf1a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=complex64, numpy=\n",
              "array([[ 0.8541581 +5.1853675e-01j,  0.7038202 -2.5583676e-01j,\n",
              "         1.        +5.2028248e-17j,  0.41965923+6.3354260e-01j,\n",
              "         0.0552639 +4.5191187e-01j],\n",
              "       [ 1.        +0.0000000e+00j,  0.5081815 +1.8659671e-01j,\n",
              "        -0.04914504-3.7141296e-01j, -0.07774837+5.8677137e-01j,\n",
              "        -0.29802477-9.4293857e-01j]], dtype=complex64)>"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General H matrix in the ansatz:"
      ],
      "metadata": {
        "id": "F2XHk3VWH3W6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ttH=[[0.8, 0.3+0.65j, 0.8 - 0.23j], [0.3-0.65j, 0.32, 0.52 +\n",
        " 0.11j], [0.8 + 0.23j, 0.52 - 0.11j, 0.29 ]]\n",
        "ttH1= [[1.0,0.0,0.0],[0.0,1.0,0.0],[0.0,0.0,1.0]]\n",
        "tH = np.array(ttH1).astype(np.complex64)\n",
        "H = tf.convert_to_tensor(tH)"
      ],
      "metadata": {
        "id": "UcAN1NOlH5-I"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss function (in progress)\n",
        "\n",
        "  # Notation:\n",
        "    # p: index of points in a batch\n",
        "    # I: holomorphic gauge index of B\n",
        "    # J: anti-holomorphic gauge index of B\n",
        "    # i: holomorphic gauge index of V\n",
        "    # j: anti-holomorphic gauge index of V\n",
        "    # A: holomorphic gradient of spacetime on P^3\n",
        "    # B: anti-holomorphic gradient of spacetime on P^3\n",
        "    # a: holomorphic gradient of spacetime on X\n",
        "    # b: anti-holomorphic gradient of spacetime on X\n",
        "\n"
      ],
      "metadata": {
        "id": "ktik1hdsHvlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def lossB3(tpoints, Omega_Omegabar, mass, restriction, cymetric, R2s, R3s):\n",
        "    \n",
        "    with tf.GradientTape(persistent=True) as g: \n",
        "        g.watch(tpoints)\n",
        "        Sbs = modelB3(tpoints)\n",
        "        tSbs = tf.complex(Sbs[:,0:12], Sbs[:,12:24])\n",
        "    # Here you can have the other code for Svs1, tSvs1, inG, etc.\n",
        "    # Since you’re not taking derivatives of them, you can put them either\n",
        "    # inside or outside the with statement\n",
        "    # However, if you are going to take derivatives of them, make sure\n",
        "    # they are calculated within a with block (or after ensuring the tape is recording)\n",
        "\n",
        "    dSb = cd.batch_jacobian_dz(g, tSbs, tpoints)\n",
        "\n",
        "    invCYmetric = tf.linalg.inv(cymetric)\n",
        "    \n",
        "\n",
        "    SbsM = tf.stack([tSbs[:,0:4],tSbs[:,4:8],tSbs[:,8:12]], 1)\n",
        "    SvsM = tf.einsum('piI,pMI->pMi', R2s,SbsM)\n",
        "    inG = tf.einsum('pjM,pMi->pji',\n",
        "        tf.einsum('pNj,NM->pjM',tf.math.conj(SvsM),H),SvsM)\n",
        "    G = tf.linalg.inv(inG)\n",
        "\n",
        "\n",
        "    dSbM = tf.stack([dSb[:,0:4],dSb[:,4:8],dSb[:,8:12]], 1)\n",
        "    tdSvM = tf.einsum('piI,pMIA->pMiA',R2s,dSbM)\n",
        "    dSvM = tf.add(tdSvM, tf.einsum('pAiI,pMI->pMiA',R3s, SbsM))\n",
        "    DSvM = tf.einsum('paA,pMiA->pMia', restriction, dSvM)\n",
        "\n",
        "    \n",
        "    # 1st term  \n",
        "    tddinG = tf.einsum('pjbM, pMia -> pjiba',\n",
        "        tf.einsum('pNjb,NM->pjbM',tf.math.conj(DSvM),H),DSvM)\n",
        "    \n",
        "    ddinG = tf.einsum('pba,pjiba->pji', invCYmetric, tddinG)\n",
        "\n",
        "    # 2nd term\n",
        "    dinG1 = tf.einsum('pjM, pMia -> pjia',\n",
        "        tf.einsum('pNj,NM->pjM',tf.math.conj(SvsM), H),DSvM)\n",
        "    \n",
        "    dinG2 = tf.einsum('pjMb, pMi -> pjib',\n",
        "        tf.einsum('pNjb,NM->pjMb',tf.math.conj(DSvM), H),SvsM)\n",
        "    \n",
        "    tddGGG = tf.einsum('pjka,pkib->pjiab', \n",
        "                       tf.einsum('pjia,pik->pjka',dinG1, G), dinG2)\n",
        "    \n",
        "    ddGGG = tf.einsum('pba,pjiab->pji',invCYmetric, tddGGG)\n",
        "\n",
        "    twM = tf.einsum('pji,pik->pjk', tf.math.subtract(ddGGG,ddinG), G)\n",
        "\n",
        "    # 1st loss function \n",
        "    tL1 = tf.math.pow(tf.abs(tf.math.subtract(twM[:,0,0], twM[:,1,1])),2)/2.0 + tf.math.add(tf.math.pow(tf.abs(twM[:,0,1]),2) , tf.math.pow(tf.abs(twM[:,1,0]),2))\n",
        "    # volX = tf.reduce_sum(mass).numpy()\n",
        "    # weights = mass / tf.math.reduce_sum(mass)\n",
        "    weights = mass / tf.reduce_sum(mass)\n",
        "    L1 = tf.einsum('p,p->',tL1,weights)\n",
        "\n",
        "    # 2nd loss function\n",
        "    # L2 = tf.math.reduce_sum(tf.math.divide(1.0, tf.math.pow(tf.math.abs(SvsM),2)))\n",
        "    \n",
        "    # w1=1.0\n",
        "    # w2=0.0\n",
        "    # L = tf.math.add(w1*L1,w2*L2)\n",
        "    \n",
        "    return L1\n",
        "\n"
      ],
      "metadata": {
        "id": "4PSbJWfmDzNR"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QJPYw9w_2bM"
      },
      "source": [
        "# Train the bundle model \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "KuJa8-75_z1p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76c39d10-7b74-413a-b7d4-b9e551184e1a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-95-1df423c1f6f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOmega_Omegabar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcymetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR2s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR3s\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasetBtrain_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlossB3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpoints\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOmega_Omegabar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestriction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcymetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR2s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR3s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelB3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'MatrixInverse_1' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 577, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 606, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 556, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-92-039a1145072e>\", line 20, in <module>\n      loss = lossB3(tpoints, Omega_Omegabar, mass, restriction, cymetric, R2s, R3s)\n    File \"<ipython-input-82-b62bcf513b50>\", line 23, in lossB3\n      G = tf.linalg.inv(inG)\nNode: 'MatrixInverse_1'\nInput is not invertible.\n\t [[{{node MatrixInverse_1}}]] [Op:__forward_lossB3_991336]"
          ]
        }
      ],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "# loss_func = mlg.loss.weighted_MAPE\n",
        "\n",
        "max_epochs = 1\n",
        "epoch = 0\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "            initial_learning_rate=0.1,\n",
        "            decay_steps = 100000,\n",
        "            decay_rate = 0.5\n",
        "            )\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "\n",
        "\n",
        "while epoch < max_epochs:\n",
        "    epoch = epoch + 1\n",
        "    for step, (tpoints, Omega_Omegabar, mass, restriction, cymetric, R2s, R3s) in enumerate(datasetBtrain_batch):\n",
        "        print(step)\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = lossB3(tpoints, Omega_Omegabar, mass, restriction, cymetric, R2s, R3s)\n",
        "            grads = tape.gradient(loss, modelB3.trainable_weights)\n",
        "           \n",
        "        optimizer.apply_gradients(zip(grads, modelB3.trainable_weights))\n",
        "    # if epoch % 1 == 0:\n",
        "    #     print(\"epoch %d: loss = %.5f\" % (epoch, loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ttt = modelB3(tpoints)\n",
        "ttt[1:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HrLMmorG70-",
        "outputId": "65154205-3930-4991-9cde-b0942d896299"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 24), dtype=float32, numpy=\n",
              "array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
              "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
              "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
              "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as g: \n",
        "        g.watch(tpoints)\n",
        "        Sbs = modelB3(tpoints)\n",
        "        tSbs = tf.complex(Sbs[:,0:12], Sbs[:,12:24])\n",
        "        dSb = cd.batch_jacobian_dz(g, tSbs, tpoints)\n",
        "    \n",
        "    \n",
        "invCYmetric = tf.linalg.inv(cymetric)\n",
        "    \n",
        "\n",
        "SbsM = tf.stack([tSbs[:,0:4],tSbs[:,4:8],tSbs[:,8:12]], 1)\n",
        "SvsM = tf.einsum('piI,pMI->pMi', R2s,SbsM)\n",
        "inG = tf.einsum('pjM,pMi->pji',\n",
        "        tf.einsum('pNj,NM->pjM',tf.math.conj(SvsM),H),SvsM)\n",
        "G = tf.linalg.inv(inG)\n",
        "\n",
        "\n",
        "dSbM = tf.stack([dSb[:,0:4],dSb[:,4:8],dSb[:,8:12]], 1)\n",
        "tdSvM = tf.einsum('piI,pMIA->pMiA',R2s,dSbM)\n",
        "dSvM = tf.add(tdSvM, tf.einsum('pAiI,pMI->pMiA',R3s, SbsM))\n",
        "DSvM = tf.einsum('paA,pMiA->pMia', restriction, dSvM)\n",
        "\n",
        "    \n",
        "# 1st term  \n",
        "tddinG = tf.einsum('pjbM, pMia -> pjiba', tf.einsum('pNjb,NM->pjbM',tf.math.conj(DSvM),H),DSvM)\n",
        "    \n",
        "ddinG = tf.einsum('pba,pjiba->pji', invCYmetric, tddinG)\n",
        "\n",
        "# 2nd term\n",
        "dinG1 = tf.einsum('pjM, pMia -> pjia',tf.einsum('pNj,NM->pjM',tf.math.conj(SvsM), H),DSvM)\n",
        "    \n",
        "dinG2 = tf.einsum('pjMb, pMi -> pjib',tf.einsum('pNjb,NM->pjMb',tf.math.conj(DSvM), H),SvsM)\n",
        "    \n",
        "tddGGG = tf.einsum('pjka,pkib->pjiab', \n",
        "                       tf.einsum('pjia,pik->pjka',dinG1, G), dinG2)\n",
        "    \n",
        "ddGGG = tf.einsum('pba,pjiab->pji',invCYmetric, tddGGG)\n",
        "\n",
        "twM = tf.einsum('pji,pik->pjk', tf.math.subtract(ddGGG,ddinG), G)\n",
        "\n",
        "    \n",
        "\n",
        "        \n",
        "\n",
        "tL1 = tf.math.pow(tf.abs(tf.math.subtract(twM[:,0,0], twM[:,1,1])),2)/2.0 + tf.math.add(tf.math.pow(tf.abs(twM[:,0,1]),2) , tf.math.pow(tf.abs(twM[:,1,0]),2))\n",
        "    \n",
        "weights = mass / tf.reduce_sum(mass)\n",
        "L1 = tf.einsum('p,p->',tL1,weights)\n",
        "\n",
        "\n",
        "L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "RtktJE-_Mfsq",
        "outputId": "da1c1fdf-ae88-45de-dd1f-ceb6c49eba37"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-7fc69343496a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m inG = tf.einsum('pjM,pMi->pji',\n\u001b[1;32m     16\u001b[0m         tf.einsum('pNj,NM->pjM',tf.math.conj(SvsM),H),SvsM)\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_linalg_ops.py\u001b[0m in \u001b[0;36mmatrix_inverse\u001b[0;34m(input, adjoint, name)\u001b[0m\n\u001b[1;32m   1504\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7184\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7185\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7186\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Input is not invertible. [Op:MatrixInverse]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "modelB3 = SectionCY3B3()\n",
        "tpoints[0:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zo8F42pVjmB5",
        "outputId": "0d879b35-4415-4cad-e1fe-ef308c6aef40"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 5), dtype=complex64, numpy=\n",
              "array([[ 0.80755895-0.58261585j, -0.4637045 +0.13295728j,\n",
              "         1.        -0.j        , -0.27136084-0.20586745j,\n",
              "        -0.26203746-0.19624402j],\n",
              "       [-0.31140676+0.90590733j,  0.0254997 -0.18712038j,\n",
              "        -0.2967851 -0.6958547j ,  0.48480016-0.01826854j,\n",
              "         1.        +0.j        ]], dtype=complex64)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " Sbs = modelB3(tpoints)\n",
        " Sbs[0:2]"
      ],
      "metadata": {
        "id": "9G52VgcRjmOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44927328-4dc9-4f58-b411-5483916acb0d"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 24), dtype=float32, numpy=\n",
              "array([[ 0.05335655,  0.0304739 ,  0.12512514, -0.05349746, -0.05094995,\n",
              "        -0.03738218, -0.0562264 ,  0.03788488,  0.01043772, -0.04013002,\n",
              "        -0.10015127,  0.02587775, -0.07982294, -0.05224958,  0.04158115,\n",
              "        -0.00054767,  0.06031071,  0.06170193,  0.0357704 , -0.01053821,\n",
              "        -0.09719668, -0.06419479,  0.01127916,  0.07326891],\n",
              "       [ 0.05950587, -0.0752193 , -0.11848453, -0.01341702, -0.01165547,\n",
              "        -0.13672815,  0.02360401, -0.03816806,  0.11709575,  0.03189908,\n",
              "        -0.08864836, -0.01345418, -0.00606438,  0.08152582,  0.05334831,\n",
              "        -0.09800752,  0.07943001,  0.13751385, -0.03535741, -0.05347095,\n",
              "         0.07477321, -0.13354476,  0.0137938 ,  0.14491966]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as g: \n",
        "        g.watch(tpoints)\n",
        "        Sbs = modelB3(tpoints)\n",
        "        tSbs = tf.complex(Sbs[:,0:12], Sbs[:,12:24])\n",
        "        dSb = cd.batch_jacobian_dz(g, tSbs, tpoints)\n",
        "    \n",
        "    \n",
        "invCYmetric = tf.linalg.inv(cymetric)\n",
        "    \n",
        "\n",
        "SbsM = tf.stack([tSbs[:,0:4],tSbs[:,4:8],tSbs[:,8:12]], 1)\n",
        "SvsM = tf.einsum('piI,pMI->pMi', R2s,SbsM)\n",
        "inG = tf.einsum('pjM,pMi->pji',\n",
        "        tf.einsum('pNj,NM->pjM',tf.math.conj(SvsM),H),SvsM)\n",
        "G = tf.linalg.inv(inG)\n",
        "\n",
        "dSbM = tf.stack([dSb[:,0:4],dSb[:,4:8],dSb[:,8:12]], 1)\n",
        "tdSvM = tf.einsum('piI,pMIA->pMiA',R2s,dSbM)\n",
        "dSvM = tf.add(tdSvM, tf.einsum('pAiI,pMI->pMiA',R3s, SbsM))\n",
        "DSvM = tf.einsum('paA,pMiA->pMia', restriction, dSvM)\n",
        "\n",
        "# 1st term  \n",
        "tddinG = tf.einsum('pjbM, pMia -> pjiba', tf.einsum('pNjb,NM->pjbM',tf.math.conj(DSvM),H),DSvM)\n",
        "    \n",
        "ddinG = tf.einsum('pba,pjiba->pji', invCYmetric, tddinG)\n",
        "\n",
        "# 2nd term\n",
        "dinG1 = tf.einsum('pjM, pMia -> pjia',tf.einsum('pNj,NM->pjM',tf.math.conj(SvsM), H),DSvM)\n",
        "    \n",
        "dinG2 = tf.einsum('pjMb, pMi -> pjib',tf.einsum('pNjb,NM->pjMb',tf.math.conj(DSvM), H),SvsM)\n",
        "    \n",
        "tddGGG = tf.einsum('pjka,pkib->pjiab', \n",
        "                       tf.einsum('pjia,pik->pjka',dinG1, G), dinG2)\n",
        "    \n",
        "ddGGG = tf.einsum('pba,pjiab->pji',invCYmetric, tddGGG)\n",
        "\n",
        "twM = tf.einsum('pji,pik->pjk', tf.math.subtract(ddGGG,ddinG), G)\n",
        "\n",
        "# substract the trace\n",
        "traceM = tf.linalg.trace(twM)\n",
        "idenM = tf.cast(tf.eye(rank),tf.complex64)\n",
        "\n",
        "ttraceMs = []\n",
        "for trM in traceM:\n",
        "  ttraceMs.append(tf.math.scalar_mul(trM,idenM))\n",
        "traceMM = tf.stack(ttraceMs)\n",
        "\n",
        "Mm = tf.math.subtract(twM,traceMM)\n",
        "# Frobenius norm of a matrix \n",
        "tL1 = tf.cast(tf.norm(Mm, ord='fro', axis=[1,2]),tf.float32)\n",
        "\n",
        "weights = mass / tf.reduce_sum(mass)\n",
        "L1 = tf.einsum('p,p->',tL1,weights)\n"
      ],
      "metadata": {
        "id": "HYQg2eDv5vUB"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### zero-trace for rank-3 bundle:"
      ],
      "metadata": {
        "id": "dz-Zm--29p89"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SectionCY3B3(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(SectionCY3B3, self).__init__()\n",
        "        # The first layer transforms the complex points to the bihomogeneous form.\n",
        "        # The number of the outputs is d^2, where d is the number of coordinates.\n",
        "        self.bihomogeneous = bnn.Bihomogeneous()\n",
        "        self.layer1 = bnn.Dense(5**2, 100, activation=tf.square)\n",
        "        # self.layer2 = bnn.Dense(20, 30, activation=tf.square)\n",
        "        # self.layer3 = bnn.Dense(30, 50, activation=tf.square)\n",
        "        # self.layer4 = bnn.Dense(70, 80, activation=tf.square)\n",
        "        self.layer5 = bnn.Dense(100, 24)\n",
        "        \n",
        "    \n",
        "    def call(self, inputs):\n",
        "        x = self.bihomogeneous(inputs)\n",
        "        x = self.layer1(x)\n",
        "        # x = self.layer2(x)\n",
        "        # x = self.layer3(x)\n",
        "        # x = self.layer4(x)\n",
        "        x = self.layer5(x)\n",
        "        return x\n",
        "\n",
        "modelB3 = SectionCY3B3()"
      ],
      "metadata": {
        "id": "ALnHxCKeJ0lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape(persistent=True) as g: \n",
        "        g.watch(tpoints)\n",
        "        Sbs = modelB3(tpoints)\n",
        "        tSbs = tf.complex(Sbs[:,0:12], Sbs[:,12:24])\n",
        "        dSb = cd.batch_jacobian_dz(g, tSbs, tpoints)\n",
        "    \n",
        "    \n",
        "invCYmetric = tf.linalg.inv(cymetric)\n",
        "    \n",
        "\n",
        "SbsM = tf.stack([tSbs[:,0:4],tSbs[:,4:8],tSbs[:,8:12]], 1)\n",
        "SvsM = tf.einsum('piI,pMI->pMi', R2s,SbsM)\n",
        "inG = tf.einsum('pjM,pMi->pji',\n",
        "        tf.einsum('pNj,NM->pjM',tf.math.conj(SvsM),H),SvsM)\n",
        "G = tf.linalg.inv(inG)\n",
        "\n",
        "dSbM = tf.stack([dSb[:,0:4],dSb[:,4:8],dSb[:,8:12]], 1)\n",
        "tdSvM = tf.einsum('piI,pMIA->pMiA',R2s,dSbM)\n",
        "dSvM = tf.add(tdSvM, tf.einsum('pAiI,pMI->pMiA',R3s, SbsM))\n",
        "DSvM = tf.einsum('paA,pMiA->pMia', restriction, dSvM)\n",
        "\n",
        "# 1st term  \n",
        "tddinG = tf.einsum('pjbM, pMia -> pjiba', tf.einsum('pNjb,NM->pjbM',tf.math.conj(DSvM),H),DSvM)\n",
        "    \n",
        "ddinG = tf.einsum('pba,pjiba->pji', invCYmetric, tddinG)\n",
        "\n",
        "# 2nd term\n",
        "dinG1 = tf.einsum('pjM, pMia -> pjia',tf.einsum('pNj,NM->pjM',tf.math.conj(SvsM), H),DSvM)\n",
        "    \n",
        "dinG2 = tf.einsum('pjMb, pMi -> pjib',tf.einsum('pNjb,NM->pjMb',tf.math.conj(DSvM), H),SvsM)\n",
        "    \n",
        "tddGGG = tf.einsum('pjka,pkib->pjiab', \n",
        "                       tf.einsum('pjia,pik->pjka',dinG1, G), dinG2)\n",
        "    \n",
        "ddGGG = tf.einsum('pba,pjiab->pji',invCYmetric, tddGGG)\n",
        "\n",
        "twM = tf.einsum('pji,pik->pjk', tf.math.subtract(ddGGG,ddinG), G)\n",
        "tf.linalg.trace(twM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDQtAxVx9uQZ",
        "outputId": "549da8c0-a319-4e81-84d0-9425c5737fc9"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1000,), dtype=complex64, numpy=\n",
              "array([ 2.00000000e+00-9.53125000e-01j, -2.38418579e-07+2.98023224e-08j,\n",
              "        1.52587891e-05+1.52587891e-05j,  7.42187500e-02+1.31835938e-02j,\n",
              "        0.00000000e+00+9.53674316e-07j,  1.78813934e-06+3.57627869e-07j,\n",
              "        8.34465027e-07+8.94069672e-08j,  1.14440918e-05+1.90734863e-06j,\n",
              "       -9.53674316e-06+5.72204590e-06j,  2.00000000e+00+1.25000000e-01j,\n",
              "       -8.78906250e-03+2.25830078e-03j, -4.57763672e-05-4.91142273e-05j,\n",
              "       -1.43051147e-06+7.15255737e-07j,  9.91821289e-05-2.28881836e-05j,\n",
              "       -6.29145600e+06-1.25829120e+07j,  1.22070312e-04-1.22070312e-04j,\n",
              "        0.00000000e+00+4.76837158e-07j,  6.10351562e-05+4.57763672e-05j,\n",
              "       -7.62939453e-06+3.81469727e-06j,  7.62939453e-05+1.76429749e-05j,\n",
              "        2.38418579e-06+2.14576721e-06j,  0.00000000e+00+6.10351562e-05j,\n",
              "       -1.19209290e-05-2.62260437e-06j,  5.72204590e-06-4.76837158e-07j,\n",
              "        4.68750000e-02+1.52343750e-01j,  1.90734863e-06-2.86102295e-06j,\n",
              "        4.02832031e-03-1.40571594e-03j, -2.71797180e-05-2.26497650e-05j,\n",
              "       -4.57763672e-05-1.14440918e-05j, -1.09863281e-03-2.51770020e-04j,\n",
              "       -9.53674316e-07+2.08616257e-06j, -6.10351562e-05-1.38282776e-05j,\n",
              "       -1.66015625e-02-3.90625000e-03j,  6.67572021e-06-4.76837158e-07j,\n",
              "       -3.05175781e-05-7.15255737e-06j, -4.17232513e-07-2.38418579e-07j,\n",
              "        0.00000000e+00+3.05175781e-03j, -3.81469727e-06+2.14576721e-05j,\n",
              "       -7.74860382e-06+4.76837158e-07j,  2.28881836e-04+2.47955322e-05j,\n",
              "       -1.90734863e-06+9.53674316e-07j,  3.81469727e-05-5.72204590e-06j,\n",
              "       -1.33514404e-05+1.43051147e-06j, -5.00000000e-01+5.00000000e-01j,\n",
              "        2.38418579e-07-5.96046448e-08j, -7.62939453e-05+7.82012939e-05j,\n",
              "        3.32031250e-02+1.23214722e-02j, -1.20000000e+02-3.17500000e+01j,\n",
              "        2.98023224e-07+0.00000000e+00j,  0.00000000e+00-3.33786011e-06j,\n",
              "       -1.90734863e-06+3.57627869e-07j,  1.22070312e-04-1.52587891e-05j,\n",
              "        2.86102295e-06+1.43051147e-06j, -1.44958496e-04+3.12805176e-04j,\n",
              "       -9.76562500e-04-7.32421875e-04j,  4.29153442e-06+5.96046448e-07j,\n",
              "       -4.57763672e-05+0.00000000e+00j, -8.10623169e-06-1.19209290e-06j,\n",
              "       -5.12000000e+02-6.40000000e+01j, -6.91413879e-05-7.62939453e-06j,\n",
              "        3.81469727e-06+2.86102295e-06j,  1.18255615e-04+1.52587891e-05j,\n",
              "       -1.90734863e-06-2.38418579e-07j, -7.62939453e-06-3.81469727e-06j,\n",
              "        1.56250000e-02-5.00488281e-03j,  4.19616699e-05-3.14712524e-05j,\n",
              "       -1.66893005e-05-8.34465027e-07j,  1.33514404e-05-1.78813934e-06j,\n",
              "       -1.29699707e-04-6.22272491e-05j, -3.05175781e-05+1.09672546e-05j,\n",
              "       -4.00000000e+01+7.00000000e+00j,  4.76837158e-07-8.58306885e-06j,\n",
              "       -3.05175781e-04+2.82287598e-04j, -2.56347656e-02+2.10571289e-03j,\n",
              "       -4.76837158e-07-1.19209290e-07j,  1.90734863e-05+4.76837158e-06j,\n",
              "        3.81469727e-06+1.90734863e-06j,  1.90734863e-06+9.53674316e-07j,\n",
              "       -2.38418579e-06+4.76837158e-07j,  7.62939453e-06-4.76837158e-07j,\n",
              "        1.33514404e-05+3.68058681e-06j,  1.22070312e-04+0.00000000e+00j,\n",
              "        8.77380371e-05-3.05175781e-05j,  1.52587891e-04+3.43322754e-05j,\n",
              "       -9.53674316e-07+0.00000000e+00j,  1.52587891e-05+7.62939453e-06j,\n",
              "       -3.57627869e-07-7.45058060e-08j,  0.00000000e+00-8.39233398e-05j,\n",
              "        0.00000000e+00+0.00000000e+00j,  1.04904175e-05-5.72204590e-06j,\n",
              "        1.37329102e-04-8.15391541e-05j,  5.72204590e-06+2.50339508e-06j,\n",
              "        1.25169754e-06+4.47034836e-08j,  3.81469727e-06-1.14440918e-05j,\n",
              "       -3.20000000e+01+0.00000000e+00j,  2.47955322e-05-9.53674316e-07j,\n",
              "       -3.43322754e-05-1.90734863e-05j, -1.28746033e-05-9.53674316e-07j,\n",
              "        1.46484375e-03+3.05175781e-04j, -6.25000000e-02-6.68945312e-02j,\n",
              "       -1.90734863e-06-4.76837158e-07j, -1.43051147e-06-5.96046448e-08j,\n",
              "        3.24249268e-05-3.33786011e-05j,  5.48362732e-06-7.15255737e-07j,\n",
              "        4.76837158e-07-1.78813934e-07j,  1.43051147e-06-7.15255737e-07j,\n",
              "        2.09808350e-05-2.28881836e-05j,  8.54492188e-04-2.44140625e-04j,\n",
              "        9.53674316e-07+2.38418579e-06j,  2.28881836e-05+8.58306885e-06j,\n",
              "       -4.05311584e-06+1.19209290e-07j,  2.50000000e-01+0.00000000e+00j,\n",
              "        1.19209290e-06+2.38418579e-07j,  1.14440918e-05+4.48226929e-05j,\n",
              "       -9.53674316e-07-2.53319740e-07j,  3.87430191e-07-7.15255737e-07j,\n",
              "        5.72204590e-06-2.38418579e-05j,  2.86102295e-05+1.23977661e-05j,\n",
              "        9.53674316e-07+4.76837158e-07j,  2.67028809e-05+8.58306885e-06j,\n",
              "       -2.38418579e-07+7.15255737e-07j, -6.67572021e-06-8.10623169e-06j,\n",
              "       -1.58691406e-03+5.49316406e-04j,  0.00000000e+00+1.90734863e-05j,\n",
              "       -1.46484375e-03+8.54492188e-04j,  1.04904175e-05+2.90870667e-05j,\n",
              "        9.05990601e-06+1.90734863e-06j,  0.00000000e+00-1.83105469e-04j,\n",
              "       -2.92968750e-03+0.00000000e+00j,  1.56250000e-02+3.90625000e-03j,\n",
              "       -2.83122063e-07-2.98023224e-08j,  2.68554688e-03-6.10351562e-05j,\n",
              "        2.47955322e-04-9.15527344e-05j, -1.95312500e-03-2.44140625e-03j,\n",
              "       -9.77516174e-06-4.76837158e-07j,  4.15039062e-03+2.13623047e-04j,\n",
              "       -7.62939453e-06-5.72204590e-06j, -3.41796875e-03+7.32421875e-04j,\n",
              "        7.62939453e-05+6.10351562e-05j,  1.90734863e-05+5.24520874e-06j,\n",
              "       -2.44140625e-04-1.22070312e-04j,  1.28746033e-05-5.72204590e-06j,\n",
              "        4.39453125e-03-1.52587891e-03j, -1.13248825e-06-2.98023224e-07j,\n",
              "       -9.37500000e-02+1.56250000e-02j,  3.09944153e-06-2.98023224e-07j,\n",
              "        1.23977661e-05+2.38418579e-07j, -9.53674316e-07-2.32458115e-06j,\n",
              "       -1.33514404e-05-2.38418579e-07j, -2.86102295e-05+5.96046448e-06j,\n",
              "       -2.86102295e-06+6.67572021e-06j,  8.34465027e-07-2.98023224e-07j,\n",
              "        8.00000000e+00+2.00000000e+00j,  1.19209290e-07-1.78813934e-07j,\n",
              "        1.43051147e-06-1.43051147e-06j, -2.74658203e-04+1.14440918e-05j,\n",
              "        3.81469727e-06+2.98023224e-08j, -1.14440918e-05-9.53674316e-07j,\n",
              "       -1.19209290e-07+3.57627869e-07j, -3.81469727e-06-7.15255737e-07j,\n",
              "       -1.14440918e-05-2.57492065e-05j,  2.47955322e-05-4.17232513e-07j,\n",
              "        9.53674316e-07-1.32918358e-05j,  1.66893005e-06+7.74860382e-07j,\n",
              "        3.27825546e-07+0.00000000e+00j,  1.20699406e-06+2.38418579e-07j,\n",
              "        6.25000000e-02-3.12500000e-02j,  3.05175781e-04+2.44140625e-04j,\n",
              "        2.05993652e-04+1.62124634e-04j, -7.62939453e-06-8.77380371e-05j,\n",
              "       -1.22070312e-04-6.48498535e-05j, -2.00271606e-05-3.33786011e-06j,\n",
              "        1.34277344e-03+9.91821289e-05j,  2.38418579e-06+2.38418579e-06j,\n",
              "        4.76837158e-06+1.19209290e-06j, -9.76562500e-04+1.22070312e-04j,\n",
              "       -2.92968750e-03-9.76562500e-04j,  8.39233398e-05+2.76565552e-05j,\n",
              "       -6.86645508e-05-5.72204590e-06j,  7.62939453e-06+1.52587891e-05j,\n",
              "       -3.81469727e-06-1.02818012e-06j, -6.19888306e-06+2.38418579e-07j,\n",
              "        1.43051147e-06-8.94069672e-08j, -1.66400000e+03-7.04000000e+02j,\n",
              "       -2.09808350e-05+5.23775816e-06j,  8.34465027e-07+2.98023224e-08j,\n",
              "        2.38418579e-07-5.96046448e-07j,  2.02655792e-06+3.57627869e-07j,\n",
              "        1.52587891e-05-2.71797180e-05j,  1.02996826e-04+8.82148743e-06j,\n",
              "       -2.28881836e-05-6.67572021e-06j,  6.19888306e-06-1.43051147e-06j,\n",
              "       -4.52995300e-06-4.76837158e-07j,  6.10351562e-05-1.67846680e-04j,\n",
              "        0.00000000e+00+1.00000000e+00j,  1.52587891e-05+7.05718994e-05j,\n",
              "        0.00000000e+00+1.52587891e-05j, -9.76562500e-04+1.22070312e-04j,\n",
              "        1.19209290e-06+9.53674316e-07j, -1.90734863e-06-4.76837158e-07j,\n",
              "       -8.01086426e-05-8.34465027e-06j, -6.20000000e+01-8.00000000e+00j,\n",
              "        5.81741333e-05+1.90734863e-06j, -1.13248825e-06-5.96046448e-08j,\n",
              "       -1.78813934e-06-1.78813934e-07j,  3.62396240e-05-6.67572021e-06j,\n",
              "        3.33786011e-06-4.76837158e-07j, -7.15255737e-07-4.76837158e-07j,\n",
              "        9.53674316e-06-2.62260437e-06j, -4.76837158e-07+1.49011612e-07j,\n",
              "       -6.19888306e-06+6.67572021e-06j,  9.53674316e-07-1.43051147e-06j,\n",
              "        4.76837158e-07+3.57627869e-07j, -6.19888306e-06+0.00000000e+00j,\n",
              "       -5.96046448e-08-1.34110451e-07j,  2.14576721e-06-1.19209290e-07j,\n",
              "        3.33786011e-06-3.03983688e-06j, -3.81469727e-04+8.01086426e-05j,\n",
              "        3.81469727e-06-2.38418579e-07j, -3.33786011e-06-1.31130219e-06j,\n",
              "        1.06811523e-04+7.62939453e-06j,  1.14440918e-05-2.86102295e-06j,\n",
              "        7.62939453e-05+1.06811523e-04j,  5.34057617e-05+4.29153442e-06j,\n",
              "       -2.86102295e-06+4.76837158e-07j,  2.44140625e-04+0.00000000e+00j,\n",
              "       -5.03540039e-04+7.62939453e-05j,  8.34465027e-07-1.43051147e-06j,\n",
              "        5.72204590e-06+1.33514404e-05j,  6.19888306e-06+2.80141830e-06j,\n",
              "       -3.33786011e-06+4.76837158e-07j,  2.44140625e-04+1.22070312e-04j,\n",
              "        3.50000000e+00+2.50000000e-01j,  1.60000000e+02-3.60000000e+01j,\n",
              "       -2.00271606e-05-1.31130219e-06j, -5.72204590e-06-1.43051147e-06j,\n",
              "       -3.05175781e-05-5.96046448e-06j, -2.09808350e-05+7.15255737e-07j,\n",
              "       -1.52587891e-05+8.46385956e-06j,  4.76837158e-07-1.49011612e-07j,\n",
              "        5.79833984e-04-1.95503235e-04j,  1.04904175e-05+1.19209290e-06j,\n",
              "        7.05718994e-05-7.06613064e-05j, -1.95312500e-03-9.76562500e-04j,\n",
              "        1.14440918e-04-1.90734863e-05j,  5.72204590e-06-9.53674316e-07j,\n",
              "        2.03251839e-05-3.09944153e-06j, -5.62500000e-01-1.05468750e-01j,\n",
              "        1.33514404e-05+7.15255737e-06j,  1.14440918e-05+2.38418579e-06j,\n",
              "       -3.12500000e-02+2.81372070e-02j,  1.52587891e-05+3.81469727e-06j,\n",
              "        1.43051147e-06-7.15255737e-07j,  2.50000000e-01-1.07421875e-02j,\n",
              "       -2.81333923e-05-1.87754631e-06j, -5.96046448e-08+1.49011612e-08j,\n",
              "        2.74181366e-06-5.96046448e-07j, -9.15527344e-05-9.91821289e-05j,\n",
              "       -5.64575195e-04+7.62939453e-05j, -2.86102295e-05-1.14440918e-05j,\n",
              "        3.81469727e-06-2.62260437e-06j,  1.34277344e-03-6.56127930e-04j,\n",
              "        4.19616699e-05+2.38418579e-07j,  4.95910645e-05+8.58306885e-06j,\n",
              "       -8.34465027e-07+2.38418579e-07j, -1.87500000e-01-7.81250000e-02j,\n",
              "        6.10351562e-05-3.05175781e-05j,  2.98023224e-07-2.23517418e-08j,\n",
              "        7.81250000e-02-2.83203125e-02j,  1.14440918e-05-1.19209290e-06j,\n",
              "        6.10351562e-05-1.14440918e-05j, -7.74860382e-07+0.00000000e+00j,\n",
              "       -7.62939453e-06-1.43051147e-06j,  2.38418579e-06-2.38418579e-07j,\n",
              "        1.33514404e-05-1.90734863e-06j, -6.86645508e-05-5.72204590e-06j,\n",
              "        0.00000000e+00+3.27825546e-07j, -7.51018524e-06+1.19209290e-06j,\n",
              "        3.43322754e-05-1.71661377e-05j, -2.44140625e-03+6.10351562e-04j,\n",
              "       -1.02996826e-04+5.34057617e-05j,  2.67028809e-05+2.33650208e-05j,\n",
              "       -2.62260437e-06-4.47034836e-08j, -3.81469727e-06+5.96046448e-07j,\n",
              "        0.00000000e+00-1.89989805e-07j,  3.81469727e-05+6.67572021e-06j,\n",
              "       -4.76837158e-07+7.15255737e-07j, -2.44140625e-04+6.24656677e-04j,\n",
              "        9.53674316e-07-1.78813934e-07j, -7.62939453e-06-1.90734863e-06j,\n",
              "        0.00000000e+00-2.86102295e-05j, -5.49316406e-04-4.57763672e-05j,\n",
              "       -1.14440918e-05-2.86102295e-06j,  1.04904175e-05+1.43051147e-06j,\n",
              "        0.00000000e+00-2.16066837e-07j,  6.00000000e+00+1.00000000e+00j,\n",
              "       -1.13248825e-06+5.06639481e-07j, -2.14576721e-06-2.38418579e-07j,\n",
              "        0.00000000e+00-4.57763672e-05j,  2.28881836e-05-1.62124634e-05j,\n",
              "       -1.83105469e-04-1.22070312e-04j,  2.86102295e-06-1.90734863e-06j,\n",
              "       -5.11169434e-04-3.49044800e-04j,  0.00000000e+00-2.38418579e-07j,\n",
              "        8.01086426e-05+5.72204590e-05j, -3.05175781e-05+4.76837158e-06j,\n",
              "       -2.38418579e-06-9.53674316e-07j,  9.53674316e-07+0.00000000e+00j,\n",
              "       -5.00679016e-06-4.76837158e-06j, -6.43730164e-06+2.02655792e-06j,\n",
              "        8.77380371e-05+4.76837158e-05j, -3.75000000e-01+1.06250000e+00j,\n",
              "       -9.15527344e-05+6.96182251e-05j, -4.19616699e-05-1.09672546e-05j,\n",
              "       -3.09944153e-06-1.19209290e-07j,  2.86102295e-06-2.38418579e-07j,\n",
              "        1.90734863e-06-2.86102295e-06j,  3.35693359e-04-1.08718872e-04j,\n",
              "       -4.17232513e-06+0.00000000e+00j,  2.44140625e-04+3.62396240e-05j,\n",
              "       -1.22070312e-04-2.09808350e-05j, -2.86102295e-06-2.38418579e-07j,\n",
              "       -2.38418579e-07+4.76837158e-07j,  7.15255737e-06-7.15255737e-07j,\n",
              "       -1.95312500e-03-9.15527344e-05j, -1.78813934e-07+1.19209290e-07j,\n",
              "       -5.72204590e-06-8.34465027e-07j,  0.00000000e+00+2.98023224e-07j,\n",
              "       -7.15255737e-07-2.68220901e-07j,  1.52587891e-05-3.20672989e-05j,\n",
              "        0.00000000e+00-1.19209290e-07j,  6.25000000e-01-3.12500000e-02j,\n",
              "        3.81469727e-06-2.50339508e-06j, -1.95312500e-03-2.44140625e-04j,\n",
              "        3.81469727e-06+2.38418579e-06j, -2.13623047e-04-4.14848328e-05j,\n",
              "        1.52587891e-05+0.00000000e+00j,  7.15255737e-07-4.02331352e-07j,\n",
              "        9.53674316e-07+1.71363354e-06j,  1.87500000e-01-5.85937500e-03j,\n",
              "        2.02655792e-06+8.19563866e-08j,  9.53674316e-07+4.76837158e-07j,\n",
              "       -1.83105469e-04+1.14440918e-04j,  5.24520874e-06+1.19209290e-06j,\n",
              "        2.44140625e-04+1.22070312e-04j, -2.98023224e-07-2.98023224e-07j,\n",
              "       -9.53674316e-07+4.76837158e-07j, -1.31130219e-06-3.57627869e-07j,\n",
              "        7.15255737e-07-2.98023224e-08j, -1.58691406e-03+9.15527344e-04j,\n",
              "       -1.52587891e-05-1.78813934e-06j, -9.53674316e-06+2.86102295e-06j,\n",
              "       -1.90734863e-06+4.76837158e-07j, -1.14440918e-05+8.58306885e-06j,\n",
              "        6.67572021e-06+1.66893005e-06j, -3.52859497e-05-1.14440918e-05j,\n",
              "       -9.53674316e-06-2.92062759e-06j,  1.90734863e-05-5.72204590e-06j,\n",
              "        1.14440918e-05-1.43051147e-06j, -5.85937500e-03+1.22070312e-03j,\n",
              "       -1.22070312e-04+4.48226929e-05j, -1.20162964e-04+3.33786011e-06j,\n",
              "        5.93750000e-01+7.32421875e-02j, -4.76837158e-07-3.57627869e-07j,\n",
              "       -1.46484375e-02+1.48925781e-02j, -4.57763672e-05-6.43730164e-06j,\n",
              "       -4.19616699e-05+2.38418579e-06j, -9.53674316e-07-2.86102295e-06j,\n",
              "       -7.62939453e-06-4.57763672e-05j,  9.53674316e-07-5.96046448e-08j,\n",
              "        7.62939453e-05-3.81469727e-06j, -1.43051147e-06-9.53674316e-07j,\n",
              "        9.53674316e-07+1.43051147e-06j,  1.07288361e-06+7.15255737e-07j,\n",
              "        5.00000000e-01-6.25000000e-02j,  0.00000000e+00+5.96046448e-08j,\n",
              "        1.31130219e-06+1.31130219e-06j, -9.53674316e-06+1.19209290e-06j,\n",
              "        4.76837158e-06+4.76837158e-07j,  3.33786011e-06-8.34465027e-07j,\n",
              "        6.19888306e-06+1.19209290e-06j, -2.28881836e-05+1.32322311e-05j,\n",
              "        1.07288361e-06+1.19209290e-06j,  5.06639481e-07-1.26659870e-07j,\n",
              "        1.90734863e-06+5.72204590e-06j, -2.36511230e-04-4.95910645e-05j,\n",
              "       -4.88281250e-03+2.28881836e-03j,  1.90734863e-06+9.53674316e-07j,\n",
              "        1.19209290e-07+0.00000000e+00j,  1.43051147e-06+1.19209290e-06j,\n",
              "        1.14440918e-04+1.43051147e-05j, -7.62939453e-06+3.81469727e-06j,\n",
              "        1.63912773e-07+0.00000000e+00j,  1.90734863e-06+2.38418579e-06j,\n",
              "       -1.52587891e-05+1.14440918e-05j, -1.22070312e-02-8.30078125e-03j,\n",
              "        0.00000000e+00+0.00000000e+00j,  0.00000000e+00-4.47034836e-07j,\n",
              "       -1.36718750e-02-4.88281250e-04j,  5.34057617e-05-2.20537186e-05j,\n",
              "       -1.09672546e-05+0.00000000e+00j, -1.14440918e-05+1.90734863e-06j,\n",
              "       -7.62939453e-06-1.33514404e-05j,  1.52587891e-05+4.76837158e-06j,\n",
              "       -4.76837158e-07+0.00000000e+00j, -1.90734863e-06+2.38418579e-07j,\n",
              "        2.28881836e-05-1.71661377e-05j, -2.14576721e-06+8.94069672e-08j,\n",
              "        0.00000000e+00+2.38418579e-07j,  1.19209290e-07+7.45058060e-08j,\n",
              "        1.07288361e-06+5.21540642e-08j,  1.43051147e-06-2.38418579e-07j,\n",
              "        0.00000000e+00-2.12402344e-02j,  4.05311584e-06+2.98023224e-06j,\n",
              "        3.81469727e-06-9.53674316e-07j,  2.59399414e-04+7.62939453e-05j,\n",
              "       -1.14440918e-05+2.86102295e-06j,  1.50000000e+00-1.75000000e+00j,\n",
              "       -3.33786011e-06+0.00000000e+00j, -5.53131104e-05-1.43051147e-06j,\n",
              "       -5.36441803e-07-1.15018338e-07j,  1.76429749e-05+0.00000000e+00j,\n",
              "       -2.86102295e-06-2.14576721e-06j,  4.76837158e-07+3.42726707e-07j,\n",
              "        3.57627869e-07+5.36441803e-07j, -7.62939453e-06+5.72204590e-06j,\n",
              "        1.52587891e-04+1.06811523e-04j,  6.86645508e-05-1.95503235e-05j,\n",
              "       -5.34057617e-05-1.52587891e-05j, -3.81469727e-06+9.53674316e-07j,\n",
              "        7.15255737e-07-3.57627869e-07j,  5.00679016e-06-2.62260437e-06j,\n",
              "        0.00000000e+00+5.12000000e+02j,  8.10623169e-06-2.62260437e-06j,\n",
              "       -1.46484375e-03+2.21252441e-04j,  5.24520874e-06+2.83122063e-07j,\n",
              "        4.76837158e-07+1.19209290e-07j,  4.57763672e-05+2.29835510e-04j,\n",
              "       -9.15527344e-05+4.38690186e-05j,  8.34465027e-07-2.98023224e-08j,\n",
              "       -3.81469727e-06+9.53674316e-07j, -7.93457031e-04+2.13623047e-04j,\n",
              "        1.46484375e-03+5.41687012e-04j,  3.05175781e-05-2.09808350e-05j,\n",
              "        1.33514404e-05-1.90734863e-06j,  1.71661377e-05+1.90734863e-06j,\n",
              "        1.19209290e-06+3.57627869e-07j, -1.43051147e-06-3.21865082e-06j,\n",
              "       -3.81469727e-06+0.00000000e+00j,  1.90734863e-06+1.37090683e-05j,\n",
              "        7.15255737e-07-4.76837158e-07j, -3.81469727e-06-2.86102295e-06j,\n",
              "        4.76837158e-06+0.00000000e+00j,  3.81469727e-06+3.45706940e-06j,\n",
              "       -9.53674316e-07+3.57627869e-07j, -4.57763672e-05+4.68790531e-05j,\n",
              "        2.44140625e-04+3.05175781e-04j,  0.00000000e+00+2.98023224e-08j,\n",
              "        0.00000000e+00-1.54972076e-06j,  3.90625000e-03-3.90625000e-03j,\n",
              "        1.14440918e-05+5.72204590e-06j,  3.05175781e-05+2.76565552e-05j,\n",
              "        7.32421875e-04+3.05175781e-05j, -5.72204590e-06+2.86102295e-06j,\n",
              "       -7.15255737e-07+5.96046448e-08j, -9.53674316e-07-2.08616257e-07j,\n",
              "        4.95910645e-05-1.04904175e-05j,  9.53674316e-07-2.14576721e-06j,\n",
              "        3.33786011e-06+3.03983688e-06j, -6.10351562e-05+1.47819519e-05j,\n",
              "        7.62939453e-06-2.62260437e-06j,  2.09808350e-05+4.23192978e-06j,\n",
              "        3.90625000e-02-3.90625000e-03j,  2.28881836e-05+0.00000000e+00j,\n",
              "       -7.62939453e-06-1.60932541e-06j,  0.00000000e+00+2.25000000e+00j,\n",
              "       -1.52587891e-05-2.67028809e-05j,  1.22070312e-04+3.91006470e-05j,\n",
              "        6.10351562e-05+2.67028809e-05j,  2.38418579e-07+4.47034836e-08j,\n",
              "        4.52995300e-06+3.81469727e-06j, -2.28881836e-05-4.10079956e-05j,\n",
              "        1.16825104e-05-3.81469727e-06j, -5.00000000e-01-1.25000000e-01j,\n",
              "       -2.13623047e-04+9.53674316e-05j,  4.76837158e-07-8.34465027e-07j,\n",
              "       -9.15527344e-05+2.67028809e-05j,  1.83105469e-04-8.58306885e-06j,\n",
              "        2.98023224e-07+4.76837158e-07j,  5.72204590e-06-2.62260437e-06j,\n",
              "       -9.53674316e-07+1.90734863e-06j,  4.27246094e-04-2.74658203e-04j,\n",
              "       -2.20537186e-06-1.03563070e-06j, -7.62939453e-05+9.53674316e-05j,\n",
              "        1.90734863e-06-1.43051147e-06j, -9.53674316e-07-5.96046448e-08j,\n",
              "       -1.25000000e-01-3.90625000e-02j, -2.09808350e-05-5.72204590e-06j,\n",
              "        0.00000000e+00+2.38418579e-07j,  3.81469727e-05+1.90734863e-06j,\n",
              "        1.19209290e-07-2.98023224e-08j, -1.90734863e-06-2.38418579e-07j,\n",
              "       -2.86102295e-06+7.15255737e-07j,  1.98364258e-04-2.08854675e-04j,\n",
              "       -8.39233398e-05+1.45435333e-05j, -7.62939453e-06+4.76837158e-07j,\n",
              "       -9.53674316e-06-9.53674316e-06j, -3.20000000e+01-1.25000000e+00j,\n",
              "        7.62939453e-06+1.43051147e-06j,  4.76837158e-07-4.17232513e-07j,\n",
              "        2.67028809e-05-5.72204590e-06j, -7.81250000e-03-1.95312500e-02j,\n",
              "        4.76837158e-06-4.05311584e-06j,  0.00000000e+00-7.15255737e-07j,\n",
              "        4.76837158e-07+1.78813934e-07j, -1.52587891e-05-5.14984131e-05j,\n",
              "        7.81250000e-03-9.76562500e-03j,  2.50000000e-01-6.25000000e-02j,\n",
              "       -1.56250000e-02+1.17187500e-02j,  1.43051147e-06+2.38418579e-07j,\n",
              "        1.09863281e-03+2.82287598e-04j,  1.90734863e-05-9.53674316e-07j,\n",
              "       -4.76837158e-06+2.38418579e-06j,  9.76562500e-04+4.04357910e-04j,\n",
              "       -2.67028809e-05+1.62124634e-05j,  1.90734863e-06-9.53674316e-07j,\n",
              "       -3.05175781e-04+1.37329102e-04j,  0.00000000e+00-3.90625000e-02j,\n",
              "       -1.81198120e-05+4.29153442e-06j, -4.19616699e-05-6.67572021e-06j,\n",
              "        3.81469727e-06+1.07288361e-06j,  1.14440918e-05+1.43051147e-06j,\n",
              "       -5.96046448e-07+0.00000000e+00j,  1.14440918e-05-2.05039978e-05j,\n",
              "        4.19616699e-05+6.19888306e-06j,  3.81469727e-06-1.31130219e-06j,\n",
              "        3.05175781e-05+2.74181366e-06j,  1.78813934e-07+2.53319740e-07j,\n",
              "        6.40869141e-04+3.05175781e-05j,  3.12500000e-02+8.78906250e-03j,\n",
              "       -2.14576721e-06+1.19209290e-06j, -3.81469727e-06-2.62260437e-06j,\n",
              "        2.98023224e-07-2.98023224e-08j,  1.66893005e-06+0.00000000e+00j,\n",
              "       -9.53674316e-07+1.78813934e-07j, -8.58306885e-06-9.53674316e-07j,\n",
              "        1.43051147e-06+2.38418579e-07j, -1.90734863e-06+3.33786011e-06j,\n",
              "        1.95312500e-03-3.66210938e-04j,  2.00271606e-05-2.38418579e-06j,\n",
              "       -1.49011612e-07-4.76837158e-07j, -3.81469727e-05+3.81469727e-06j,\n",
              "       -4.76837158e-07-1.49011612e-07j,  6.55651093e-07+1.78813934e-07j,\n",
              "       -9.53674316e-06-6.55651093e-07j, -2.74658203e-04+7.62939453e-05j,\n",
              "        4.57763672e-05-2.28881836e-05j, -1.23977661e-05-9.53674316e-07j,\n",
              "        8.34465027e-07+7.15255737e-07j, -5.96046448e-07+2.98023224e-07j,\n",
              "        1.66893005e-06-5.96046448e-08j, -6.10351562e-05-3.81469727e-05j,\n",
              "        4.57763672e-05-2.28881836e-05j, -7.15255737e-07-2.68220901e-07j,\n",
              "        3.81469727e-06+5.72204590e-06j,  2.50000000e-01+7.42187500e-01j,\n",
              "        7.62939453e-06-6.83963299e-06j,  2.28881836e-05+5.72204590e-06j,\n",
              "        2.86102295e-06+1.43051147e-06j, -1.14440918e-05-3.33786011e-06j,\n",
              "        1.43051147e-06-2.08616257e-07j, -3.33786011e-06+1.43051147e-06j,\n",
              "        9.76562500e-04+2.44140625e-04j,  2.86102295e-06+5.96046448e-08j,\n",
              "        2.28881836e-05+3.81469727e-06j,  3.90625000e-02-1.56250000e-02j,\n",
              "       -1.22070312e-04-6.10351562e-04j,  7.62939453e-06-7.15255737e-06j,\n",
              "        0.00000000e+00+3.09199095e-07j,  2.44140625e-04+6.10351562e-05j,\n",
              "       -4.57763672e-05+1.60217285e-04j,  1.46484375e-02-8.30078125e-03j,\n",
              "       -2.57492065e-05+1.14440918e-05j, -7.15255737e-06+4.76837158e-06j,\n",
              "       -2.38418579e-07-4.76837158e-07j, -7.15255737e-07+3.57627869e-07j,\n",
              "       -7.62939453e-06+1.10626221e-04j, -1.43051147e-06-1.01327896e-06j,\n",
              "        2.50339508e-06-4.76837158e-07j,  1.71661377e-05-9.53674316e-07j,\n",
              "       -3.81469727e-06-2.86102295e-06j,  1.46484375e-03+7.70568848e-04j,\n",
              "       -7.62939453e-06+2.38418579e-06j, -2.18750000e-01+5.85937500e-03j,\n",
              "        5.45382500e-06-5.96046448e-08j,  2.38418579e-07+6.33299351e-08j,\n",
              "       -3.81469727e-06-1.90734863e-06j, -3.12500000e-02+2.92968750e-03j,\n",
              "       -3.05175781e-05-3.81469727e-06j,  8.58306885e-06+1.90734863e-06j,\n",
              "       -4.76837158e-06-4.76837158e-07j, -6.55651093e-07+0.00000000e+00j,\n",
              "        4.57763672e-05+6.29425049e-05j,  5.72204590e-05-6.29425049e-05j,\n",
              "       -4.76837158e-07+0.00000000e+00j, -6.10351562e-05+1.52587891e-05j,\n",
              "        0.00000000e+00+5.77419996e-08j, -1.14440918e-05+0.00000000e+00j,\n",
              "        2.86102295e-06-1.43051147e-06j, -9.53674316e-07+1.07288361e-06j,\n",
              "       -3.81469727e-06-2.38418579e-06j, -4.57763672e-05+2.67028809e-05j,\n",
              "        4.76837158e-07-1.19209290e-07j, -9.76562500e-04+2.44140625e-04j,\n",
              "        6.67572021e-06+3.21865082e-06j, -1.04904175e-05-1.10268593e-06j,\n",
              "        2.86102295e-06-1.07288361e-06j,  5.06639481e-07+1.49011612e-07j,\n",
              "       -4.76837158e-06+1.54972076e-06j,  2.92968750e-03+1.70898438e-03j,\n",
              "       -8.58306885e-06+2.62260437e-06j,  1.90734863e-06-5.72204590e-06j,\n",
              "       -7.62939453e-06+0.00000000e+00j, -2.38418579e-07+3.57627869e-07j,\n",
              "        2.38418579e-06+1.90734863e-06j,  6.10351562e-05+3.81469727e-06j,\n",
              "       -2.38418579e-07+2.53319740e-07j, -6.40000000e+01+1.60000000e+01j,\n",
              "        5.72204590e-06-1.90734863e-06j, -1.78813934e-06-1.90734863e-06j,\n",
              "       -1.14440918e-05+8.58306885e-06j, -1.52587891e-03-1.81579590e-03j,\n",
              "       -7.15255737e-07-2.08616257e-07j, -4.76837158e-06-2.38418579e-07j,\n",
              "       -5.46875000e-02+1.56250000e-02j, -6.43730164e-06-4.17232513e-07j,\n",
              "        1.52587891e-05-1.52587891e-05j, -1.43051147e-06-2.98023224e-08j,\n",
              "        7.81250000e-03-2.44140625e-04j, -1.83105469e-04+1.52587891e-05j,\n",
              "        9.53674316e-07-2.38418579e-07j,  3.05175781e-05-8.58306885e-06j,\n",
              "        1.67846680e-04-5.34057617e-05j,  0.00000000e+00-1.78813934e-06j,\n",
              "        1.22070312e-03-8.54492188e-04j,  3.33786011e-05+1.90734863e-06j,\n",
              "        0.00000000e+00-3.81469727e-06j,  1.19209290e-06-1.66893005e-06j,\n",
              "       -1.52587891e-05+3.33786011e-06j, -4.32133675e-06-1.01327896e-06j,\n",
              "       -5.34057617e-05+1.90734863e-06j,  7.62939453e-05-1.14440918e-05j,\n",
              "        9.76562500e-04-9.15527344e-05j, -1.90734863e-06+8.34465027e-07j,\n",
              "        5.49316406e-04-1.52587891e-04j,  8.82148743e-06+1.78813934e-07j,\n",
              "        0.00000000e+00+4.76837158e-07j, -6.55651093e-06-1.19209290e-06j,\n",
              "        4.76837158e-07-5.36441803e-07j, -2.38418579e-05+2.86102295e-06j,\n",
              "       -7.62939453e-06-7.62939453e-06j,  2.38418579e-06-1.07288361e-06j,\n",
              "       -7.62939453e-05-9.53674316e-05j,  3.81469727e-06+7.15255737e-07j,\n",
              "       -7.62939453e-06+1.19209290e-07j,  3.57627869e-07-1.19209290e-07j,\n",
              "        3.05175781e-05-9.53674316e-07j,  2.86102295e-06+1.19209290e-06j,\n",
              "        2.38418579e-05+4.29153442e-06j,  9.53674316e-07-4.76837158e-07j,\n",
              "        1.43051147e-06-9.53674316e-07j,  8.82148743e-06+1.43051147e-06j,\n",
              "        2.86102295e-06-4.76837158e-06j, -6.19888306e-06-1.66893005e-06j,\n",
              "       -9.53674316e-07+8.34465027e-07j, -9.91821289e-05+0.00000000e+00j,\n",
              "       -8.34465027e-07-5.30853868e-07j, -2.38418579e-06+4.76837158e-07j,\n",
              "       -4.57763672e-05+2.05039978e-04j,  4.29153442e-06+5.96046448e-07j,\n",
              "        1.43051147e-06-1.43051147e-06j, -1.95312500e-03+9.76562500e-04j,\n",
              "        3.12500000e-01+1.25000000e-01j,  1.41601562e-02+4.88281250e-04j,\n",
              "        1.29699707e-04-2.28881836e-05j, -1.98364258e-04-5.72204590e-05j,\n",
              "        7.32421875e-04+5.34057617e-05j, -4.29153442e-06+4.76837158e-07j,\n",
              "        0.00000000e+00+9.53674316e-06j, -1.52587891e-05-9.53674316e-07j,\n",
              "        9.53674316e-07-1.90734863e-06j,  5.96046448e-08+2.38418579e-07j,\n",
              "        2.19345093e-05+1.19209290e-06j, -4.88281250e-04+1.15966797e-03j,\n",
              "        3.57627869e-07-6.55651093e-07j,  1.66893005e-05-3.09944153e-06j,\n",
              "       -4.29153442e-06-1.75833702e-06j, -5.12000000e+02-5.76000000e+02j,\n",
              "       -8.80000000e+01-8.00000000e+00j, -1.90734863e-06-5.96046448e-06j,\n",
              "        4.00000000e+01+8.00000000e+00j, -1.04904175e-05+4.76837158e-07j,\n",
              "       -3.66210938e-04-3.05175781e-05j,  1.85600000e+03+1.78200000e+03j,\n",
              "        2.38418579e-06+1.43051147e-06j, -2.38418579e-07-2.38418579e-07j,\n",
              "        3.05175781e-05+1.12056732e-05j, -9.05990601e-06+5.24520874e-06j,\n",
              "        9.53674316e-07-1.43051147e-06j,  1.07288361e-06+7.45058060e-08j,\n",
              "        0.00000000e+00+3.09944153e-06j,  4.76837158e-06+9.53674316e-07j,\n",
              "        2.67028809e-05+6.19888306e-05j, -1.90734863e-06+1.78813934e-06j,\n",
              "       -9.53674316e-07-4.76837158e-07j, -5.34057617e-05+1.38282776e-05j,\n",
              "        2.07519531e-03-5.26428223e-04j,  1.02400000e+03+0.00000000e+00j,\n",
              "        2.09808350e-05+1.43051147e-05j,  0.00000000e+00+1.16415322e-07j,\n",
              "        1.22070312e-04+0.00000000e+00j,  9.53674316e-07+1.90734863e-06j,\n",
              "        4.76837158e-07-4.47034836e-08j,  9.39941406e-03+1.05285645e-03j,\n",
              "       -1.90734863e-06-2.38418579e-07j, -9.15527344e-05+0.00000000e+00j,\n",
              "       -2.44140625e-03+4.88281250e-04j,  3.81469727e-06+4.76837158e-06j,\n",
              "       -1.62124634e-05-8.22544098e-06j, -9.53674316e-07-1.17346644e-07j,\n",
              "       -1.60217285e-04-4.76837158e-05j, -9.53674316e-07+0.00000000e+00j,\n",
              "       -4.88281250e-04-5.87463379e-04j, -3.05175781e-05+6.48498535e-05j,\n",
              "       -6.10351562e-05-2.28881836e-05j, -6.25000000e-02-1.56250000e-02j,\n",
              "        6.43730164e-06+1.43051147e-06j, -3.51667404e-06-5.96046448e-08j,\n",
              "        1.19209290e-07+2.98023224e-07j,  1.33514404e-05-2.86102295e-06j,\n",
              "       -1.66893005e-06-4.76837158e-07j,  9.15527344e-05+1.60217285e-04j,\n",
              "        6.70552254e-07+0.00000000e+00j,  0.00000000e+00+2.72750854e-04j,\n",
              "        7.62939453e-06+3.81469727e-05j, -7.93457031e-04+8.31604004e-04j,\n",
              "       -9.53674316e-06+6.67572021e-06j, -1.71661377e-05-2.14576721e-06j,\n",
              "        3.96728516e-04-1.52587891e-04j,  1.00135803e-05-4.29153442e-06j,\n",
              "        3.81469727e-05+6.10351562e-05j,  3.43322754e-05+1.04904175e-05j,\n",
              "        6.55651093e-07+0.00000000e+00j, -1.40380859e-03-4.04357910e-04j,\n",
              "        4.76837158e-06-2.74181366e-06j,  1.66893005e-06-7.15255737e-07j,\n",
              "        4.11987305e-04+8.01086426e-05j, -5.18560410e-06-1.49011612e-06j,\n",
              "        1.19209290e-06+5.96046448e-08j, -8.10623169e-06+5.24520874e-06j,\n",
              "       -1.95312500e-02+0.00000000e+00j, -3.57627869e-07+1.93715096e-07j,\n",
              "       -2.86102295e-06+1.19209290e-06j,  0.00000000e+00+6.10351562e-05j,\n",
              "       -1.33514404e-05-2.19345093e-05j, -1.43051147e-06-5.96046448e-07j,\n",
              "       -3.81469727e-06+2.44379044e-05j,  5.72204590e-06-6.29425049e-05j,\n",
              "       -3.81469727e-04+2.59399414e-04j,  1.43051147e-06-6.55651093e-07j,\n",
              "       -3.35693359e-04+1.29699707e-04j, -4.52995300e-06-2.98023224e-07j,\n",
              "       -8.00000000e+00+0.00000000e+00j, -8.20159912e-05+3.43322754e-05j,\n",
              "       -9.53674316e-05+3.05175781e-05j, -3.57627869e-06+4.47034836e-07j,\n",
              "       -2.38418579e-07-9.53674316e-07j, -4.76837158e-06+9.53674316e-07j,\n",
              "       -6.10351562e-05+7.05718994e-05j,  1.33514404e-05-1.51991844e-06j,\n",
              "        1.90734863e-06+2.08616257e-07j,  6.19888306e-06+2.56299973e-06j,\n",
              "        3.81469727e-06+1.90734863e-06j,  7.62939453e-06-5.72204590e-06j,\n",
              "       -2.38418579e-07+1.19209290e-07j,  3.12500000e-02+1.02539062e-02j,\n",
              "        9.53674316e-07+2.38418579e-07j, -1.43051147e-06-1.19209290e-06j,\n",
              "        7.74860382e-07+1.19209290e-07j,  5.49316406e-04+1.52587891e-05j,\n",
              "       -5.72204590e-06-9.53674316e-07j,  6.71386719e-04+1.83105469e-04j,\n",
              "       -4.06250000e-01-6.44531250e-02j,  0.00000000e+00+4.47034836e-08j,\n",
              "        2.13623047e-04+1.52587891e-05j,  1.33514404e-05-2.38418579e-05j,\n",
              "       -1.52587891e-05+7.39097595e-06j,  1.52587891e-05-1.90734863e-06j,\n",
              "        2.38418579e-06-7.15255737e-07j, -3.33786011e-06+6.91413879e-06j,\n",
              "        0.00000000e+00-3.90625000e-03j, -4.76837158e-06+2.96160579e-07j,\n",
              "        5.53131104e-05+4.76837158e-06j, -1.25000000e-01+3.12500000e-02j,\n",
              "        4.29687500e-02-2.28271484e-02j, -2.28881836e-05+3.27825546e-07j,\n",
              "        3.14712524e-05-1.90734863e-06j,  1.19209290e-07+5.96046448e-08j,\n",
              "        7.62939453e-06+4.76837158e-07j,  4.76837158e-07+5.66244125e-07j,\n",
              "       -6.19888306e-06-1.49011612e-07j, -5.72204590e-06+3.01003456e-06j,\n",
              "       -7.62939453e-06-2.86102295e-06j,  0.00000000e+00-9.53674316e-07j,\n",
              "       -9.53674316e-07-5.96046448e-07j, -9.53674316e-07+3.57627869e-06j,\n",
              "        3.05175781e-05+3.81469727e-06j, -2.86102295e-06-1.26063824e-05j,\n",
              "        0.00000000e+00-1.66893005e-06j,  4.76837158e-07+1.20699406e-06j,\n",
              "       -1.43051147e-06+7.15255737e-07j,  5.24520874e-06+0.00000000e+00j,\n",
              "        1.95312500e-03+7.32421875e-04j,  2.86102295e-06-9.53674316e-07j,\n",
              "        3.57627869e-07+5.96046448e-07j, -3.57627869e-07+1.19209290e-06j,\n",
              "        3.96728516e-04+3.05175781e-05j,  0.00000000e+00-1.90734863e-06j,\n",
              "       -3.21865082e-06+1.07288361e-06j,  1.90734863e-06-2.86102295e-06j,\n",
              "        1.66893005e-06-7.15255737e-07j, -5.72204590e-06+2.14576721e-06j,\n",
              "        3.66210938e-04-1.90734863e-05j,  4.76837158e-07-5.96046448e-08j,\n",
              "       -3.12500000e-02-3.12500000e-02j,  1.14440918e-05-4.00543213e-05j,\n",
              "       -8.58306885e-06-6.43730164e-06j, -1.14440918e-04-4.76837158e-05j,\n",
              "        8.58306885e-06+2.32458115e-06j,  4.76837158e-07+5.96046448e-08j,\n",
              "       -7.62939453e-05-6.10351562e-05j,  2.28881836e-05-2.86102295e-06j,\n",
              "        7.62939453e-06+9.53674316e-07j, -1.19209290e-06+2.38418579e-07j,\n",
              "        3.35693359e-04-2.86102295e-05j,  2.13623047e-04+2.59399414e-04j,\n",
              "        3.90625000e-03-5.85937500e-03j,  2.74658203e-04+4.57763672e-05j,\n",
              "       -4.57763672e-05+1.14440918e-05j, -1.90734863e-06-4.29153442e-06j,\n",
              "       -5.72204590e-06-4.76837158e-07j, -1.00135803e-05+3.21865082e-06j,\n",
              "        2.14576721e-05-8.58306885e-06j,  9.76562500e-04-6.10351562e-05j,\n",
              "        2.95639038e-05-1.28746033e-05j,  2.44140625e-03+1.70898438e-03j,\n",
              "       -4.76837158e-07-2.38418579e-07j, -1.48773193e-04+2.67028809e-05j,\n",
              "        9.53674316e-07+1.90734863e-06j, -4.76837158e-07+1.13248825e-06j,\n",
              "        1.43051147e-06-3.57627869e-07j, -3.05175781e-05-9.53674316e-06j,\n",
              "       -1.33514404e-05-6.19888306e-06j,  2.38418579e-07-7.45058060e-08j,\n",
              "        9.05990601e-06+0.00000000e+00j, -7.62939453e-06+0.00000000e+00j,\n",
              "        3.35693359e-04-7.62939453e-06j, -2.38418579e-07+1.41561031e-07j,\n",
              "       -1.71661377e-05-2.00271606e-05j, -6.33239746e-04-1.52587891e-05j,\n",
              "       -1.14440918e-05-1.90734863e-06j, -1.46484375e-03+2.86865234e-03j,\n",
              "       -9.91821289e-05+2.08616257e-05j,  1.04904175e-05-1.90734863e-06j,\n",
              "       -3.57627869e-07-3.57627869e-07j,  2.28881836e-05-3.57627869e-06j,\n",
              "       -1.78813934e-06-3.57627869e-07j,  7.15255737e-06-1.90734863e-06j,\n",
              "       -3.35693359e-04+1.25885010e-04j,  2.92968750e-03+5.85937500e-03j,\n",
              "        3.20434570e-04+1.68085098e-05j,  8.00000000e+01+1.00000000e+00j,\n",
              "       -7.62939453e-06+2.23517418e-06j,  9.53674316e-07+4.76837158e-07j,\n",
              "        1.90734863e-06-2.86102295e-06j, -1.01327896e-06+6.92903996e-07j,\n",
              "       -1.66893005e-06-1.78813934e-07j, -1.43051147e-06+5.96046448e-07j,\n",
              "       -1.52587891e-05+7.03334808e-06j,  4.76837158e-06+1.19209290e-07j,\n",
              "       -7.62939453e-06-3.81469727e-06j,  9.53674316e-07-4.29153442e-06j,\n",
              "       -3.12500000e-02-1.22070312e-03j,  5.96046448e-07-2.08616257e-07j,\n",
              "        8.34465027e-07-1.19209290e-07j, -3.05175781e-05-6.86645508e-05j,\n",
              "        2.14576721e-06-1.43051147e-06j, -1.62124634e-05+2.98023224e-06j,\n",
              "        7.15255737e-07-1.19209290e-07j,  4.76837158e-06+1.43051147e-06j,\n",
              "        7.15255737e-07-1.19209290e-07j,  4.76837158e-07+2.38418579e-06j,\n",
              "       -2.98023224e-07+2.38418579e-07j, -3.57627869e-07+5.96046448e-08j,\n",
              "       -4.76837158e-07-5.96046448e-08j,  6.00000000e+00+0.00000000e+00j,\n",
              "        0.00000000e+00-7.86781311e-06j, -4.88281250e-04+3.05175781e-04j,\n",
              "        1.66893005e-06-1.19209290e-07j,  3.81469727e-06+7.15255737e-07j,\n",
              "       -1.19209290e-07+0.00000000e+00j, -1.90734863e-04-1.28746033e-04j,\n",
              "       -7.62939453e-06+1.90734863e-06j,  3.66210938e-04+1.06811523e-04j,\n",
              "       -6.10351562e-04-1.22070312e-04j,  4.76837158e-06+1.90734863e-06j,\n",
              "        7.62939453e-06+1.33514404e-05j,  9.53674316e-07+0.00000000e+00j,\n",
              "        9.53674316e-06+3.33786011e-06j,  1.09672546e-05+1.19209290e-06j,\n",
              "        9.15527344e-05-8.01086426e-05j,  2.38418579e-06-1.90734863e-06j,\n",
              "       -1.00000000e+00+2.75000000e+00j,  9.53674316e-07-1.19209290e-07j,\n",
              "       -1.13248825e-06+9.53674316e-07j,  1.52587891e-05+0.00000000e+00j,\n",
              "       -3.81469727e-06+1.66893005e-06j,  1.52587891e-03+1.83105469e-04j,\n",
              "        5.36441803e-07+8.94069672e-08j, -7.62939453e-05-2.28881836e-05j,\n",
              "       -1.25000000e-01+0.00000000e+00j,  9.53674316e-06-2.09808350e-05j,\n",
              "        3.05175781e-04-1.67846680e-04j,  4.88281250e-04+1.95312500e-03j,\n",
              "        6.25000000e-02-3.90625000e-02j, -7.62939453e-06-3.09944153e-06j,\n",
              "        2.71797180e-05-3.81469727e-06j,  1.62124634e-05-7.74860382e-06j,\n",
              "       -4.29153442e-06+1.19209290e-06j,  9.15527344e-05+4.52995300e-05j,\n",
              "       -3.81469727e-06+1.43051147e-06j,  2.38418579e-07-5.96046448e-08j,\n",
              "       -3.81469727e-05-2.09808350e-05j, -2.38418579e-07-5.96046448e-07j,\n",
              "        2.38418579e-07+1.26659870e-07j,  7.62939453e-06-1.33514404e-05j,\n",
              "       -1.90734863e-06+3.57627869e-06j, -1.90734863e-05+0.00000000e+00j,\n",
              "       -3.81469727e-06-2.38418579e-06j,  3.14712524e-05-1.19209290e-05j,\n",
              "        5.96046448e-08-6.70552254e-08j,  2.67028809e-05+9.53674316e-06j,\n",
              "        1.52587891e-05-8.58306885e-06j, -1.90734863e-05-6.67572021e-06j,\n",
              "       -1.19209290e-06+1.49011612e-07j, -6.67572021e-06+1.43051147e-06j,\n",
              "        1.26953125e-02-1.95312500e-03j, -1.43051147e-05+8.08387995e-07j,\n",
              "       -9.15527344e-05-2.28881836e-05j,  1.84320000e+04-1.84320000e+04j,\n",
              "        1.90734863e-06-8.10623169e-06j,  0.00000000e+00+1.31130219e-06j,\n",
              "        2.47955322e-05+7.62939453e-06j, -1.46484375e-03+1.46484375e-03j,\n",
              "       -6.67572021e-06+1.78813934e-06j, -2.86102295e-06-1.43051147e-06j,\n",
              "        9.53674316e-07+1.07288361e-06j,  3.81469727e-06+2.86102295e-06j,\n",
              "       -1.62124634e-05+4.94718552e-06j, -1.43051147e-06-2.38418579e-07j,\n",
              "       -7.74860382e-07-4.47034836e-07j, -6.25000000e-02+1.56250000e-02j,\n",
              "       -5.24520874e-06+2.03847885e-05j,  0.00000000e+00+8.34465027e-07j,\n",
              "        2.38418579e-06-7.15255737e-07j,  4.76837158e-06-4.76837158e-07j,\n",
              "       -1.19209290e-06+1.19209290e-07j, -5.72204590e-06-1.19209290e-07j,\n",
              "       -4.57763672e-05-1.90734863e-06j,  3.05175781e-05-4.76837158e-07j,\n",
              "       -3.81469727e-05+4.72068787e-05j, -8.96000000e+02+7.68000000e+02j,\n",
              "        2.86102295e-06-4.76837158e-07j,  3.81469727e-06-2.14576721e-06j,\n",
              "        2.86102295e-05+2.86102295e-06j, -8.58306885e-06+1.00135803e-05j,\n",
              "       -3.05175781e-05-9.91821289e-05j,  3.84000000e+02+0.00000000e+00j,\n",
              "       -1.37329102e-04+2.67028809e-05j,  8.39233398e-05+3.81469727e-05j,\n",
              "       -6.25000000e-02+0.00000000e+00j,  0.00000000e+00-7.15255737e-07j,\n",
              "       -4.76837158e-07-7.15255737e-07j,  4.41074371e-06-2.38418579e-06j,\n",
              "        1.52587891e-05-1.90734863e-06j,  9.53674316e-07-2.38418579e-07j,\n",
              "        5.96046448e-07+2.42143869e-07j, -2.38418579e-07+3.57627869e-07j,\n",
              "       -2.14576721e-06+0.00000000e+00j,  1.71661377e-05+2.20537186e-06j],\n",
              "      dtype=complex64)>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pt=38\n",
        "\n",
        "tttp1 = tf.einsum('ji,ik->jk', ddGGG[pt], G[pt])\n",
        "tttp2 = tf.einsum('ji,ik->jk', ddinG[pt], G[pt])\n",
        "\n",
        "print(tttp1)\n",
        "print(tttp2)\n",
        "print(tf.linalg.trace(tttp1))\n",
        "print(tf.linalg.trace(tttp2))\n",
        "print(tttp1-tttp2)\n",
        "print(tf.linalg.eigvals(tttp1-tttp2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2hijEyXIAwc",
        "outputId": "76187c42-1477-452f-93de-790f05c12bce"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 4.7510767 +1.4103642j   3.030204  -3.0342994j  -0.91628265-1.228914j  ]\n",
            " [ 0.3262481 +1.728576j    3.0218983 +0.6300832j  -0.07408494-0.18507016j]\n",
            " [ 1.228764  +5.9632454j   6.1071544 +1.0018202j   2.290801  -2.0404458j ]], shape=(3, 3), dtype=complex64)\n",
            "tf.Tensor(\n",
            "[[ 4.30995   +0.58058107j  2.8924015 -2.7123117j  -1.9547842 +0.37980443j]\n",
            " [ 1.0052717 +0.51186275j  1.7710493 -0.59444815j -0.30938724-0.05816805j]\n",
            " [-5.919473  -1.502262j   -4.4048996 +3.888932j    3.9827845 +0.01386831j]], shape=(3, 3), dtype=complex64)\n",
            "tf.Tensor((10.063776+1.4305115e-06j), shape=(), dtype=complex64)\n",
            "tf.Tensor((10.063784+1.2284145e-06j), shape=(), dtype=complex64)\n",
            "tf.Tensor(\n",
            "[[ 0.44112682+0.8297831j   0.1378026 -0.32198763j  1.0385015 -1.6087184j ]\n",
            " [-0.67902356+1.2167132j   1.250849  +1.2245314j   0.2353023 -0.1269021j ]\n",
            " [ 7.148237  +7.4655075j  10.512054  -2.8871117j  -1.6919835 -2.0543141j ]], shape=(3, 3), dtype=complex64)\n",
            "tf.Tensor(\n",
            "[ 0.34363103-9.9548606e-07j  4.395129  +8.4619541e-07j\n",
            " -4.7387657 -1.7881393e-07j], shape=(3,), dtype=complex64)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ML_HYM_CY3.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}